{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-24T11:37:16.093695Z",
     "end_time": "2023-05-24T11:37:17.215023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Error_Compare import *\n",
    "from Time_series_alignment_functions import *\n",
    "import analysis.dtw as cdtw\n",
    "import dtw as pdtw\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "#activity_dir = \"data/dataset/2b8f256d-7063-410c-b66d-3bdfb7d140c5\"\n",
    "#activity_dir = \"data/dataset/fa99ac972245361cf4256225cae4a2c0b80ff333\"\n",
    "activity_dir = \"data/dataset/c220e0e4-d30d-4ead-858a-1545b91bc362\"\n",
    "min_time = 60\n",
    "max_time = np.inf\n",
    "key_metrics = [\"breathTime\", \"VT\", \"instBR\"]\n",
    "lb_error_window = 3 # lower bound error window\n",
    "ra_window = 60 # rolling average error window\n",
    "ra_threshold = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T11:37:17.221230Z",
     "end_time": "2023-05-24T11:37:17.435891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled data found in activity data directory. Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "activity = os.path.split(activity_dir)[-1]\n",
    "clean_dfs = load_data(activity_dir, has_uncleaned = False)\n",
    "raw_chest = clean_dfs[\"raw_slow_df\"][[\"time\",\"c\",]]\n",
    "live_b3_df = clean_dfs[\"live_b3_df\"][key_metrics]\n",
    "pp_b3_df = clean_dfs[\"aws_b3_df\"][key_metrics]\n",
    "# Select subset of data based on min_time and max_time\n",
    "raw_chest = raw_chest[(raw_chest[\"time\"] > min_time) & (raw_chest[\"time\"] < max_time)]\n",
    "live_b3_df = live_b3_df[(live_b3_df[\"breathTime\"] > min_time) & (live_b3_df[\"breathTime\"] < max_time)]\n",
    "pp_b3_df = pp_b3_df[(pp_b3_df[\"breathTime\"] > min_time) & (pp_b3_df[\"breathTime\"] < max_time)]\n",
    "# Backfill pp nans if necessary\n",
    "# if pp_b3_df.isnull().values.any():\n",
    "#     print(\"pp_b3_df CONTAINS NaNs- backfilling\")\n",
    "#     # Get location of nans\n",
    "#     nan_locs = np.argwhere(pp_b3_df.isnull().values)\n",
    "#     nan_times = pp_b3_df[\"breathTime\"][nan_locs[:,0]]\n",
    "#     print(\"pp_b3_df Nan times: \", nan_times)\n",
    "#     pp_b3_df = pp_b3_df.fillna(method = \"bfill\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T11:37:17.448805Z",
     "end_time": "2023-05-24T11:37:18.377669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "# Method 1 Shift by an offset, and then take upperbound on the error\n",
    "test_metrics = {}\n",
    "pp_s_df = run_cleaning_process(clean_dfs[\"aws_b3_df\"][key_metrics])\n",
    "live_s_df = run_cleaning_process(clean_dfs[\"live_b3_df\"][key_metrics])\n",
    "# select only where index is between min_time and max_time\n",
    "pp_s_df = pp_s_df.loc[(pp_s_df.index >= min_time) & (pp_s_df.index <= max_time)]\n",
    "live_s_df = live_s_df.loc[(live_s_df.index >= min_time) & (live_s_df.index <= max_time)]\n",
    "# shift all live indices by -6\n",
    "live_s_df.index = live_s_df.index - 6\n",
    "# get the time range where both pp and live are valid\n",
    "min_s = max(min(pp_s_df.index), min(live_s_df.index))\n",
    "max_s = min(max(pp_s_df.index), max(live_s_df.index))\n",
    "# Apply the time range to the two dataframes\n",
    "pp_s_df = pp_s_df.loc[(pp_s_df.index >= min_s) & (pp_s_df.index <= max_s)]\n",
    "live_s_df = live_s_df.loc[(live_s_df.index >= min_s) & (live_s_df.index <= max_s)]\n",
    "\n",
    "# Compute (percent) positive error for pp to live\n",
    "pp_lb_error, pp_percent_error = compute_lower_bound_error(pp_s_df[\"VT\"].to_numpy(), live_s_df[\"VT\"].to_numpy(), lb_error_window)\n",
    "# Compute the rolling average error for pp_percent_error\n",
    "pp_ra_error = compute_RAT_error(pp_percent_error, ra_threshold, ra_window)\n",
    "# Compute (percent) positive error for live to pp\n",
    "live_lb_error, live_percent_error = compute_lower_bound_error(live_s_df[\"VT\"].to_numpy(), pp_s_df[\"VT\"].to_numpy(), window = lb_error_window)\n",
    "# Compute the rolling average error for pp_percent_error\n",
    "live_ra_error = compute_RAT_error(live_percent_error, ra_threshold, ra_window)\n",
    "\n",
    "pp_error_summary = summarize_percent_error(pp_percent_error)\n",
    "live_error_summary = summarize_percent_error(live_percent_error)\n",
    "if True: # Plotting the error\n",
    "    fig = make_subplots(rows = 4, cols = 1, shared_xaxes=True, vertical_spacing=0.05, subplot_titles=(\"Raw Chest Signal\",\"Input Signals\", \"PP to Live LB Relative Percent Error\", \"Live to PP LB Relative Percent Error\"))\n",
    "    fig.update_layout(title_text=\"Method 1 Error Analysis (VT)\")\n",
    "\n",
    "    # Plot the raw chest signal\n",
    "    fig.add_trace(go.Scatter(x=raw_chest[\"time\"], y=raw_chest[\"c\"], name=\"Raw Chest Signal\", line = LINE_DICT[\"CHEST\"]), row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Chest Signal\", row=1, col=1)\n",
    "\n",
    "    # Plot the VT Signals (interpolated and live shifted in this case)\n",
    "    fig.add_trace(go.Scatter(x=live_s_df.index, y=live_s_df[\"VT\"], name=\"Live (-6s)\", line = LINE_DICT[\"LIVE\"]), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pp_s_df.index, y=pp_s_df[\"VT\"], name=\"PP (s)\", line = LINE_DICT[\"PP\"]), row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"VT\", row=2, col=1)\n",
    "\n",
    "    # plot the error\n",
    "    fig.add_trace(go.Bar(x=pp_s_df.index, y=pp_percent_error[:,0], name=\"PP to Live  LB Error\", marker_color= COLOR_DICT[\"ERROR\"]), row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pp_s_df.index, y = pp_ra_error[:,0], name=\"PP to Live RA Error\", line = LINE_DICT[\"ERROR\"]), row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Percent Positive Error\", row=3, col=1)\n",
    "    fig.update_yaxes(range=[0, 2], row=3, col=1)\n",
    "\n",
    "    # plot the error\n",
    "    fig.add_trace(go.Bar(x = live_s_df.index, y=live_percent_error[:,0], name=\"Live to PP LB Error\", marker_color= COLOR_DICT[\"ERROR\"]), row=4, col=1)\n",
    "    fig.add_trace(go.Scatter(x=live_s_df.index, y = live_ra_error[:,0], name=\"Live to PP RA Error\", line = LINE_DICT[\"ERROR\"]), row=4, col=1)\n",
    "    fig.update_yaxes(title_text=\"Percent Positive Error\", row=4, col=1)\n",
    "    fig.update_yaxes(range=[0, 2], row=4, col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Time (s)\", row=4, col=1)\n",
    "\n",
    "    fig.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T11:37:18.390549Z",
     "end_time": "2023-05-24T11:37:22.746404Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "# Repeat the same process of instBR\n",
    "# Compute (percent) positive error for pp to live\n",
    "pp_lb_error, pp_percent_error = compute_lower_bound_error(pp_s_df[\"instBR\"].to_numpy(), live_s_df[\"instBR\"].to_numpy(), lb_error_window)\n",
    "# Compute the rolling average error for pp_percent_error\n",
    "pp_ra_error = compute_RAT_error(pp_percent_error, ra_threshold, ra_window)\n",
    "# Compute (percent) positive error for live to pp\n",
    "live_lb_error, live_percent_error = compute_lower_bound_error(live_s_df[\"instBR\"].to_numpy(), pp_s_df[\"instBR\"].to_numpy(), window = lb_error_window)\n",
    "# Compute the rolling average error for pp_percent_error\n",
    "live_ra_error = compute_RAT_error(live_percent_error, ra_threshold, ra_window)\n",
    "\n",
    "pp_error_summary = summarize_lb_error(pp_percent_error)\n",
    "live_error_summary = summarize_lb_error(live_percent_error)\n",
    "if True: # Plotting the error\n",
    "    fig = make_subplots(rows = 4, cols = 1, shared_xaxes=True, vertical_spacing=0.05, subplot_titles=(\"Raw Chest Signal\",\"Input Signals\", \"PP to Live LB Relative Percent Error\", \"Live to PP LB Relative Percent Error\"))\n",
    "    fig.update_layout(title_text=\"Method 1 Error Analysis (instBR)\")\n",
    "\n",
    "    # Plot the raw chest signal\n",
    "    fig.add_trace(go.Scatter(x=raw_chest[\"time\"], y=raw_chest[\"c\"], name=\"Raw Chest Signal\", line = LINE_DICT[\"CHEST\"]), row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Chest Signal\", row=1, col=1)\n",
    "\n",
    "    # Plot the VT Signals (interpolated and live shifted in this case)\n",
    "    fig.add_trace(go.Scatter(x=live_s_df.index, y=live_s_df[\"instBR\"], name=\"Live (-6s)\", line = LINE_DICT[\"LIVE\"]), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pp_s_df.index, y=pp_s_df[\"instBR\"], name=\"PP (s)\", line = LINE_DICT[\"PP\"]), row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"instBR\", row=2, col=1)\n",
    "\n",
    "    # plot the error\n",
    "    fig.add_trace(go.Bar(x=pp_s_df.index, y=pp_percent_error[:,0], name=\"PP to Live  LB Error\", marker_color= COLOR_DICT[\"ERROR\"]), row=3, col=1)\n",
    "    fig.add_trace(go.Scatter(x=pp_s_df.index, y = pp_ra_error[:,0], name=\"PP to Live RA Error\", line = LINE_DICT[\"ERROR\"]), row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Percent Positive Error\", row=3, col=1)\n",
    "    fig.update_yaxes(range=[0, 2], row=3, col=1)\n",
    "\n",
    "    # plot the error\n",
    "    fig.add_trace(go.Bar(x = live_s_df.index, y=live_percent_error[:,0], name=\"Live to PP LB Error\", marker_color= COLOR_DICT[\"ERROR\"]), row=4, col=1)\n",
    "    fig.add_trace(go.Scatter(x=live_s_df.index, y = live_ra_error[:,0], name=\"Live to PP RA Error\", line = LINE_DICT[\"ERROR\"]), row=4, col=1)\n",
    "    fig.update_yaxes(title_text=\"Percent Positive Error\", row=4, col=1)\n",
    "    fig.update_yaxes(range=[0, 2], row=4, col=1)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Time (s)\", row=4, col=1)\n",
    "\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T11:37:22.752406Z",
     "end_time": "2023-05-24T11:37:25.915746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [],
   "source": [
    "if live_b3_df.isnull().values.any():\n",
    "    print(\"live_b3_df CONTAINS NaNs- backfilling\")\n",
    "    # Get location of nans\n",
    "    nan_locs = np.argwhere(live_b3_df.isnull().values)\n",
    "    nan_times = live_b3_df[\"breathTime\"][nan_locs[:,0]]\n",
    "    print(\"live_b3_df Nan times: \", nan_times)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T11:37:25.920355Z",
     "end_time": "2023-05-24T11:37:26.147485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pp_b3_df CONTAINS NaNs- backfilling\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[1] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[333], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Get location of nans\u001B[39;00m\n\u001B[0;32m      4\u001B[0m nan_locs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margwhere(pp_b3_df\u001B[38;5;241m.\u001B[39misnull()\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m----> 5\u001B[0m nan_times \u001B[38;5;241m=\u001B[39m \u001B[43mpp_b3_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbreathTime\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnan_locs\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpp_b3_df Nan times: \u001B[39m\u001B[38;5;124m\"\u001B[39m, nan_times)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\series.py:1007\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1004\u001B[0m     key \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(key, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[0;32m   1005\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_values(key)\n\u001B[1;32m-> 1007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_with\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\series.py:1042\u001B[0m, in \u001B[0;36mSeries._get_with\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minteger\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1039\u001B[0m     \u001B[38;5;66;03m# We need to decide whether to treat this as a positional indexer\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m     \u001B[38;5;66;03m#  (i.e. self.iloc) or label-based (i.e. self.loc)\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_should_fallback_to_positional:\n\u001B[1;32m-> 1042\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   1043\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1044\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[key]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1070\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1072\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1298\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1299\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1303\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1238\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1239\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1241\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1242\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1429\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1430\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1432\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\AlgorithmAnalysisV2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: '[1] not in index'"
     ]
    }
   ],
   "source": [
    "if pp_b3_df.isnull().values.any():\n",
    "    print(\"pp_b3_df CONTAINS NaNs- backfilling\")\n",
    "    # Get location of nans\n",
    "    nan_locs = np.argwhere(pp_b3_df.isnull().values)\n",
    "    nan_times = pp_b3_df[\"breathTime\"][nan_locs[:,0]]\n",
    "    print(\"pp_b3_df Nan times: \", nan_times)\n",
    "    #pp_b3_df = pp_b3_df.fillna(method = \"bfill\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T10:44:41.884794Z",
     "end_time": "2023-05-24T10:44:42.009793Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if pp_s_df and live_s_df are the same length\n",
    "print(len(pp_s_df))\n",
    "print(len(live_s_df))\n",
    "# Check if any indices repeat in pp_s_df\n",
    "print(len(pp_s_df.index.unique()))\n",
    "# Check if any indices repeat in live_s_df\n",
    "print(len(live_s_df.index.unique()))\n",
    "# find the different in indices between pp_s_df and live_s_df\n",
    "print(len(set(pp_s_df.index.unique()) - set(live_s_df.index.unique())))\n",
    "# get the max and min index of pp_s_df\n",
    "print(f\"pp max index {pp_s_df.index.max()}\")\n",
    "print(f\"pp min index {pp_s_df.index.min()}\")\n",
    "# get the max and min index of live_s_df\n",
    "print(f\"live max index {live_s_df.index.max()}\")\n",
    "print(f\"live min index {live_s_df.index.min()}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-24T10:44:42.009793Z",
     "end_time": "2023-05-24T10:44:42.138791Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
